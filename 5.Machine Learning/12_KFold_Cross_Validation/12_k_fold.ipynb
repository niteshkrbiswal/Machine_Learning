{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:green;' align='left'>Cross Validation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We worked on iris data set ,we can classify those flowers using \n",
    "2. logistics rgeresiion, support vector machine(svm),decisson tree,random forest\n",
    "3. cross validation is a technique which will help in find out which model out of these is the best \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why to use k fold cross validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There is 2 option to do train and test\n",
    "2. in Case - 1 we give 100 question to a student for training and test him in exam for these 100 question \n",
    "3. in case -2 we give 70 question to a student for training and remainging 30 we give for testing (so we can get proper evaluation)\n",
    "4. But there is a issue ( what if 70 question comes from 1 subject and remaining 30 question comes from another subject ,he may fail in exam)\n",
    "5. so here in this case we use a 3rd approch named k fold classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kfold.png\" width=\"700\" height=\"500\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here in k-fold we do number of exams and avg the score of that exams \n",
    "2. in this in 1st exam we take first 20 sample as test then note the score\n",
    "3. in 2nd exam we take next 20 sample as test then note score\n",
    "4. After 5th exam we took avg of all the 5 scores as of now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # log regression\n",
    "from sklearn.svm import SVC # support vector machine\n",
    "from sklearn.tree import DecisionTreeClassifier # decission tree\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits=load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(digits.data,digits.target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Holdout validation Approch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APL73176-NITESHKUMAR\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9611111111111111"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # log regression\n",
    "log_model=LogisticRegression()\n",
    "log_model.fit(x_train,y_train)\n",
    "log_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851851851851852"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # support vector machine\n",
    "svm_model=SVC()\n",
    "svm_model.fit(x_train,y_train)\n",
    "svm_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8518518518518519"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # support vector machine\n",
    "svm_model=DecisionTreeClassifier()\n",
    "svm_model.fit(x_train,y_train)\n",
    "svm_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9685185185185186"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # support vector machine\n",
    "svm_model=RandomForestClassifier()\n",
    "svm_model.fit(x_train,y_train)\n",
    "svm_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the value getting changed for every time we run , we cannot decide which model is better by running it in a single time , so we need to run it multiple times to get the better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold Cross validation by (cross-val score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # log regression\n",
    "from sklearn.svm import SVC # support vector machine\n",
    "from sklearn.tree import DecisionTreeClassifier # decission tree\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DecisionTreeClassifier()\n",
    "kfold_val=KFold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(digits.data,digits.target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8402482929857232\n",
      "0.7821229050279329\n",
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "results=cross_val_score(model,digits.data,digits.target,cv=kfold_val)\n",
    "results\n",
    "print(np.mean(results))\n",
    "print(np.min(results))\n",
    "print(np.max(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this range is very hgh we need to hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9574074074074074\n",
      "0.9888888888888889\n",
      "0.8222222222222222\n",
      "0.9740740740740741\n"
     ]
    }
   ],
   "source": [
    "#All modle in single code\n",
    "\n",
    "def get_score(model,x_train,x_test,y_train,y_test):\n",
    "    model.fit(x_train,y_train)\n",
    "    return model.score(x_test,y_test)\n",
    "\n",
    "print(get_score(LogisticRegression(max_iter=5000),x_train,x_test,y_train,y_test))\n",
    "print(get_score(SVC(),x_train,x_test,y_train,y_test))\n",
    "print(get_score(DecisionTreeClassifier(),x_train,x_test,y_train,y_test))\n",
    "print(get_score(RandomForestClassifier(),x_train,x_test,y_train,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Kfold Cross validation by (cross-val score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"stratified kfold.png\" width=\"500\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Suppose in exam we have 2 subject ,in 1st subject we have 90 chapters and in 2nd subject we have 10 chapters ,\n",
    "2. then there is a chance that in exam we get more question from subject 1 as it has 90 chapters and get less question from subject 2 as it has only 10 chapters ,\n",
    "3. So to solve this issue we use stratified k-fold cross validation where equal number with equal ration of question will come from both subject 1 7 2 ( for example if 10% question comes from every chapters from 90 in subject 1 then 10% question will also come from 10 chapters from subject 2\n",
    "4. Always use stratified cross validation when we have inblanaced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.775      0.70277778 0.79665738 0.8356546  0.80501393]\n",
      "0.7830207366140514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "s_kfold=StratifiedKFold(5)\n",
    "model=DecisionTreeClassifier()\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(digits.data,digits.target,test_size=0.3)\n",
    "results=cross_val_score(model,digits.data,digits.target,cv=s_kfold)\n",
    "print(results)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90555556 0.95555556 0.88333333 0.93333333 0.93888889 0.95\n",
      " 0.95       0.9273743  0.88268156 0.94413408]\n",
      "[0.94444444 0.98888889 0.92777778 0.96666667 0.98333333 0.98888889\n",
      " 0.98888889 0.99441341 0.96089385 0.95530726]\n",
      "[0.91666667 0.97777778 0.94444444 0.92222222 0.95555556 0.96111111\n",
      " 0.96666667 0.97765363 0.9273743  0.93854749]\n",
      "0.9270856610800745\n",
      "0.9699503414028554\n",
      "0.9488019863438858\n"
     ]
    }
   ],
   "source": [
    "#Get stratfied cross validation for all 3 model\n",
    "log_result=cross_val_score(LogisticRegression(max_iter=5000),digits.data,digits.target,cv=10)\n",
    "svm_result=cross_val_score(SVC(),digits.data,digits.target,cv=10)\n",
    "rf_result=cross_val_score(RandomForestClassifier(n_estimators=50),digits.data,digits.target,cv=10)\n",
    "\n",
    "print(log_result)\n",
    "print(svm_result)\n",
    "print(rf_result)\n",
    "print(log_result.mean())\n",
    "print(svm_result.mean())\n",
    "print(rf_result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:purple'>Exercise</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use iris flower dataset from sklearn library and use cross_val_score against following\n",
    "models to measure the performance of each. In the end figure out the model with best performance,\n",
    "1. Logistic Regression\n",
    "2. SVM\n",
    "3. Decision Tree\n",
    "4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "[0.96666667 0.96666667 0.9        1.         1.        ]\n",
      "[0.96666667 0.96666667 0.9        0.96666667 1.        ]\n",
      "[0.96666667 0.96666667 0.96666667 0.93333333 1.        ]\n",
      "log_mean : 0.9733333333333334 \n",
      " dt_mean : 0.9666666666666668 \n",
      " rfc_mean : 0.9600000000000002 \n",
      " svm_mean : 0.9666666666666666\n",
      "Top performing model is :  0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "log_reg=cross_val_score(LogisticRegression(max_iter=400),iris.data,iris.target,cv=5)\n",
    "dt=cross_val_score(DecisionTreeClassifier(),iris.data,iris.target,cv=5)\n",
    "rfc=cross_val_score(RandomForestClassifier(),iris.data,iris.target,cv=5)\n",
    "svm=cross_val_score(SVC(),iris.data,iris.target,cv=5)\n",
    "\n",
    "print(log_reg)\n",
    "print(dt)\n",
    "print(rfc)\n",
    "print(svm)\n",
    "\n",
    "log_mean=log_reg.mean()\n",
    "dt_mean=dt.mean()\n",
    "rfc_mean=rfc.mean()\n",
    "svm_mean=svm.mean()\n",
    "\n",
    "print(\"log_mean :\",log_reg.mean(),\"\\n\",\"dt_mean :\",dt.mean(),\"\\n\",\"rfc_mean :\",rfc.mean(),\"\\n\",\"svm_mean :\",svm.mean())\n",
    "\n",
    "print(\"Top performing model is : \",max(log_mean,dt_mean,rfc_mean,svm_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
